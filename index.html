<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Rohan Sinha</title> <meta name="author" content="Rohan Sinha"> <meta name="description" content="Rohan Sinha's personal webpage "> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8E%83&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="GoldeneyeRohan.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications and other writing</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Rohan Sinha</span> </h1> <p class="desc"><strong> rhnsinha [at] stanford [dot] edu </strong></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?5b24eaf8f8f100f5f6aab15789c3c991" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>PhD Candidate</p> <p>Autonomous Systems Lab</p> <p>Stanford University</p> </div> </div> <div class="clearfix"> <p>I am a PhD candidate in the department of Aeronautics and Astronautics at Stanford University, where I am a member of the <strong><a href="https://stanfordasl.github.io/" rel="external nofollow noopener" target="_blank">Autonomous Systems Lab</a></strong> advised by <strong><a href="https://web.stanford.edu/~pavone/" rel="external nofollow noopener" target="_blank">Prof. Marco Pavone</a></strong>. I currently am also a student researcher at <strong><a href="https://deepmind.google/" rel="external nofollow noopener" target="_blank">Google Deepmind Robotics</a></strong>, working with <strong><a href="https://scholar.google.com/citations?user=ZGpE5cYAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sumeet Singh</a></strong> and <strong><a href="https://vikas.sindhwani.org/" rel="external nofollow noopener" target="_blank">Vikas Sindhwani</a></strong>.</p> <p>My research focuses on developing methodologies that improve the reliability of ML-enabled robotic systems, particularly when these systems encounter <strong><a href="https://arxiv.org/abs/2212.14020" rel="external nofollow noopener" target="_blank">out-of-distribution</a></strong> conditions with respect to their training data. My work on this topic was recognized with the best paper award at <strong><a href="https://roboticsconference.org/2024/program/awards/" rel="external nofollow noopener" target="_blank">RSS 2024</a></strong>. Broadly, my research interests lie at the intersection of control theory, machine learning, and applied robotics.</p> <p>Previously, I received bachelor‚Äôs degrees in Mechanical Engineering and Computer Science from the University of California, Berkeley with honors and a distinction in general scholarship. As an undergraduate, I worked on data-driven predictive control under <strong><a href="https://me.berkeley.edu/people/francesco-borrelli/" rel="external nofollow noopener" target="_blank">Prof. Francesco Borrelli</a></strong> in the <strong><a href="https://sites.google.com/berkeley.edu/mpc-lab/home" rel="external nofollow noopener" target="_blank">Model Predictive Control Lab</a></strong> and on learning control algorithms that rely on vision systems under <strong><a href="http://people.eecs.berkeley.edu/~brecht/" rel="external nofollow noopener" target="_blank">Prof. Benjamin Recht</a></strong> in the Berkeley Artificial Intelligence Lab. I have also interned as an autonomous driving engineer at Delphi (now <a href="https://motional.com/" rel="external nofollow noopener" target="_blank">Motional</a>) and as a software engineer at Amazon.</p> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%72%68%6E%73%69%6E%68%61@%73%74%61%6E%66%6F%72%64.%65%64%75" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=IeNLTUsAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/GoldeneyeRohan" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/rohan-sinha-728012147" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/RohanSinhaSU#%20your%20Twitter%20handle" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> <div class="contact-note"> </div> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jun 9, 2025</th> <td> Thrilled to organize the second workshop on <strong><a href="https://sites.google.com/stanford.edu/ood-workshop-rss-25/home?authuser=0" rel="external nofollow noopener" target="_blank">Out-of-Distribution Generalization in Robotics: Towards Reliable Learning-based Autonomy at RSS 2025</a></strong>! üìÖ Short paper submissions due 06/09/25 </td> </tr> <tr> <th scope="row">May 25, 2025</th> <td> Our paper on robot data curation, <strong><a href="https://cupid-curation.github.io/" rel="external nofollow noopener" target="_blank">CUPID</a></strong>, was awarded the <strong><a href="https://x.com/RohanSinhaSU/status/1942760498338095392" rel="external nofollow noopener" target="_blank">Best Paper Award</a></strong> at the 2025 RSS workshop on <strong><a href="https://sites.google.com/stanford.edu/robot-evaluation-rss-2025/home?authuser=0" rel="external nofollow noopener" target="_blank">Robot Evaluation for the Real World</a></strong>! </td> </tr> <tr> <th scope="row">May 2, 2025</th> <td> Thrilled to organize the first workshop on <strong><a href="https://sites.google.com/stanford.edu/safe-vlm-icra/home?authuser=0" rel="external nofollow noopener" target="_blank">Safely Leveraging VLMs in Robotics at ICRA 2025</a></strong>! üìÖ Short paper submissions due 05/02/25 </td> </tr> <tr> <th scope="row">Aug 19, 2024</th> <td> Our paper <strong><a href="https://tinyurl.com/aesop-llm" rel="external nofollow noopener" target="_blank">AESOP</a></strong>, which explores the use of LLMs to increase robot safety and reliability, won the RSS 2024 Conference‚Äôs overall <strong><a href="https://x.com/RohanSinhaSU/status/1822762251289342288" rel="external nofollow noopener" target="_blank">best paper award</a></strong>! AESOP was also featured on <strong><a href="https://www.youtube.com/watch?v=TSC_mVH5abI" rel="external nofollow noopener" target="_blank">NVidia Drive</a></strong> episode and on <strong><a href="https://techxplore.com/news/2024-08-stage-framework-llm-based-anomaly.html" rel="external nofollow noopener" target="_blank">TechXplore</a></strong>. </td> </tr> <tr> <th scope="row">Jun 22, 2024</th> <td> Started as a Student Researcher at <strong><a href="https://deepmind.google/models/gemini-robotics/" rel="external nofollow noopener" target="_blank">Google DeepMind Robotics</a></strong> with <strong><a href="https://scholar.google.com/citations?user=ZGpE5cYAAAAJ&amp;hl=en" rel="external nofollow noopener" target="_blank">Sumeet Singh</a></strong> and <strong><a href="https://vikas.sindhwani.org/" rel="external nofollow noopener" target="_blank">Vikas Sindhwani</a></strong>! </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-15 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/cupid-teaser-final.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/cupid-teaser-final.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/cupid-teaser-final.gif-1400.webp"></source> <img src="/assets/img/publication_preview/cupid-teaser-final.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="cupid-teaser-final.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="AgiaSinhaEtAl2025" class="col-sm-8"> <div class="title">CUPID: Curating Data your Robot Loves with Influence Functions</div> <div class="author"> Christopher Agia,¬†Rohan Sinha,¬†Jingyun Yang,¬†Rika Antonova,¬†Marco Pavone,¬†Haruki Nishimura,¬†Masha Itkina,¬†and¬†Jeannette Bohg</div> <div class="periodical"> <em>In 9th Annual Conference on Robot Learning (under review)</em>, 2025 </div> <div class="periodical"> üèÜ <span style="color: #8C1515; font-weight: bold;">Winner: Best Paper Award @ RSS RoboEval Workshop, 2025</span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2506.19121" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://cupid-curation.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>In robot imitation learning, policy performance is tightly coupled with the quality and composition of the demonstration data. Yet, developing a precise understanding of how individual demonstrations contribute to downstream outcomes - such as closed-loop task success or failure - remains a persistent challenge. We propose CUPID, a robot data curation method based on a novel influence function-theoretic formulation for imitation learning policies. Given a set of evaluation rollouts, CUPID estimates the influence of each training demonstration on the policy‚Äôs expected return. This enables ranking and selection of demonstrations according to their impact on the policy‚Äôs closed-loop performance. We use CUPID to curate data by 1) filtering out training demonstrations that harm policy performance and 2) subselecting newly collected trajectories that will most improve the policy. Extensive simulated and hardware experiments show that our approach consistently identifies which data drives test-time performance. For example, training with less than 33% of curated data can yield state-of-the-art diffusion policies on the simulated RoboMimic benchmark, with similar gains observed in hardware. Furthermore, hardware experiments show that our method can identify robust strategies under distribution shift, isolate spurious correlations, and even enhance the post-training of generalist robot policies.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-15 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/aesop-teaser.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/aesop-teaser.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/aesop-teaser.gif-1400.webp"></source> <img src="/assets/img/publication_preview/aesop-teaser.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="aesop-teaser.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="SinhaElhafsiEtAl2024" class="col-sm-8"> <div class="title">Real-Time Anomaly Detection and Reactive Planning with Large Language Models</div> <div class="author"> Rohan Sinha,¬†Amine Elhafsi,¬†Christopher Agia,¬†Matt Foutter,¬†Edward Schmerling,¬†and¬†Marco Pavone</div> <div class="periodical"> <em>In Robotics: Science and Systems</em>, 2024 </div> <div class="periodical"> üèÜ <span style="color: #8C1515; font-weight: bold;">Winner: Outstanding Paper Award (top 0.2%)</span> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2407.08735v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://tinyurl.com/aesop-llm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Foundation models, e.g., large language models (LLMs), trained on internet-scale data possess zero-shot generalization capabilities that make them a promising technology towards detecting and mitigating out-of-distribution failure modes of robotic systems. Fully realizing this promise, however, poses two challenges: (i) mitigating the considerable computational expense of these models such that they may be applied online, and (ii) incorporating their judgement regarding potential anomalies into a safe control framework. In this work, we present a two-stage reasoning framework: First is a fast binary anomaly classifier that analyzes observations in an LLM embedding space, which may then trigger a slower fallback selection stage that utilizes the reasoning capabilities of generative LLMs. These stages correspond to branch points in a model predictive control strategy that maintains the joint feasibility of continuing along various fallback plans to account for the slow reasoner‚Äôs latency as soon as an anomaly is detected, thus ensuring safety. We show that our fast anomaly classifier outperforms autoregressive reasoning with state-of-the-art GPT models, even when instantiated with relatively small language models. This enables our runtime monitor to improve the trustworthiness of dynamic robotic systems, such as quadrotors or autonomous vehicles, under resource and time constraints.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-15 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/sentinel-teaser-v3-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/sentinel-teaser-v3-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/sentinel-teaser-v3-1400.webp"></source> <img src="/assets/img/publication_preview/sentinel-teaser-v3.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="sentinel-teaser-v3.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="AgiaSinhaEtAl2024" class="col-sm-8"> <div class="title">Unpacking Failure Modes of Generative Policies: Runtime Monitoring of Consistency and Progress</div> <div class="author"> Christopher Agia,¬†Rohan Sinha,¬†Jingyun Yang,¬†Ziang Cao,¬†Rika Antonova,¬†Marco Pavone,¬†and¬†Jeannette Bohg</div> <div class="periodical"> <em>In 8th Annual Conference on Robot Learning</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2410.04640" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://sites.google.com/stanford.edu/sentinel" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Robot behavior policies trained via imitation learning are prone to failure under conditions that deviate from their training data. Thus, algorithms that monitor learned policies at test time and provide early warnings of failure are necessary to facilitate scalable deployment. We propose Sentinel, a runtime monitoring framework that splits the detection of failures into two complementary categories: 1) Erratic failures, which we detect using statistical measures of temporal action consistency, and 2) task progression failures, where we use Vision Language Models (VLMs) to detect when the policy confidently and consistently takes actions that do not solve the task. Our approach has two key strengths. First, because learned policies exhibit diverse failure modes, combining complementary detectors leads to significantly higher accuracy at failure detection. Second, using a statistical temporal action consistency measure ensures that we quickly detect when multimodal, generative policies exhibit erratic behavior at negligible computational cost. In contrast, we only use VLMs to detect failure modes that are less time-sensitive. We demonstrate our approach in the context of diffusion policies trained on robotic mobile manipulation domains in both simulation and the real world. By unifying temporal consistency detection and VLM runtime monitoring, Sentinel detects 18% more failures than using either of the two detectors alone and significantly outperforms baselines, thus highlighting the importance of assigning specialized detectors to complementary categories of failure.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-15 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/FSMPC.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/FSMPC.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/FSMPC.gif-1400.webp"></source> <img src="/assets/img/publication_preview/FSMPC.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="FSMPC.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="SinhaSchmerlingEtAl2023" class="col-sm-8"> <div class="title">Closing the Loop on Runtime Monitors with Fallback-Safe MPC</div> <div class="author"> <em>R. Sinha</em>,¬†E. Schmerling,¬†and¬†M. Pavone</div> <div class="periodical"> <em>In Proc. IEEE Conf. on Decision and Control</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/tbd:tbd" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a href="https://sites.google.com/stanford.edu/fallback-safe-mpc" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>When we rely on deep-learned models for robotic perception, we must recognize that these models may behave unreliably on inputs dissimilar from the training data, compromising the closed-loop system‚Äôs safety. This raises fundamental questions on how we can assess confidence in perception systems and to what extent we can take safety-preserving actions when external environmental changes degrade our perception model‚Äôs performance. Therefore, we present a framework to certify the safety of a perception-enabled system deployed in novel contexts. To do so, we leverage robust model predictive control (MPC) to control the system using the perception estimates while maintaining the feasibility of a safety-preserving fallback plan that does not rely on the perception system. In addition, we calibrate a runtime monitor using recently proposed conformal prediction techniques to certifiably detect when the perception system degrades beyond the tolerance of the MPC controller, resulting in an end-to-end safety assurance. We show that this control framework and calibration technique allows us to certify the system‚Äôs safety with orders of magnitudes fewer samples than required to retrain the perception network when we deploy in a novel context on a photo-realistic aircraft taxiing simulator. Furthermore, we illustrate the safety-preserving behavior of the MPC on simulated examples of a quadrotor. We open-source our simulation platform and provide videos of our results at our project page: \urlhttps://tinyurl.com/fallback-safe-mpc.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-15 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/timescales-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/timescales-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/timescales-1400.webp"></source> <img src="/assets/img/publication_preview/timescales.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="timescales.png" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="SinhaSharmaEtAl2022" class="col-sm-8"> <div class="title">A System-Level View on Out-of-Distribution Data in Robotics</div> <div class="author"> <em>R. Sinha</em>,¬†S. Sharma,¬†S. Banerjee,¬†T. Lew,¬†R. Luo,¬†S. M. Richards,¬†Y. Sun,¬†E. Schmerling,¬†and¬†M. Pavone</div> <div class="periodical"> <em>arXiv preprint arXiv:2212.14020</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2212.14020" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>When testing conditions differ from those represented in training data, so-called out-of-distribution (OOD) inputs can mar the reliability of learned components in the modern robot autonomy stack. Therefore, coping with OOD data is an important challenge on the path towards trustworthy learning-enabled open-world autonomy. In this paper, we aim to demystify the topic of OOD data and its associated challenges in the context of data-driven robotic systems, drawing connections to emerging paradigms in the ML community that study the effect of OOD data on learned models in isolation. We argue that as roboticists, we should reason about the overall \textitsystem-level competence of a robot as it operates in OOD conditions. We highlight key research questions around this system-level view of OOD problems to guide future research toward safe and reliable learning-enabled autonomy.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Rohan Sinha. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>